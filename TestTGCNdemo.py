import os
import sys
import urllib.request

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.lines as mlines

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input

import stellargraph as sg
import numpy as np
from stellargraph.layer import GCN_LSTM

train_rate = 0.8
seq_len = 10
pre_len = 12






def sequence_data_preparation(seq_len, pre_len, train_data, test_data):
    trainX, trainY, testX, testY = [], [], [], []

    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):
        a = train_data[:, i : i + seq_len + pre_len]
        trainX.append(a[:, :seq_len])
        trainY.append(a[:, -1])

    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):
        b = test_data[:, i : i + seq_len + pre_len]
        testX.append(b[:, :seq_len])
        testY.append(b[:, -1])

    trainX = np.array(trainX)
    trainY = np.array(trainY)
    testX = np.array(testX)
    testY = np.array(testY)

    return trainX, trainY, testX, testY













def train_test_split(data, train_portion):
    time_len = data.shape[1]
    train_size = int(time_len * train_portion)
    train_data = np.array(data.iloc[:, :train_size])
    test_data = np.array(data.iloc[:, train_size:])
    return train_data, test_data

def scale_data(train_data, test_data):
    max_speed = train_data.max()
    min_speed = train_data.min()
    train_scaled = (train_data - min_speed) / (max_speed - min_speed)
    test_scaled = (test_data - min_speed) / (max_speed - min_speed)
    return train_scaled, test_scaled

if __name__ == '__main__':
    dataset=sg.datasets.METR_LA()
    speed_data, sensor_dist_adj = dataset.load()
    num_nodes, time_len = speed_data.shape
    print("No. of sensors:", num_nodes, "\nNo of timesteps:", time_len)
    print(speed_data.head())

    train_data, test_data = train_test_split(speed_data, train_rate)
    print("Train data: ", train_data.shape)
    print("Test data: ", test_data.shape)

    train_scaled, test_scaled = scale_data(train_data, test_data)
    trainX, trainY, testX, testY = sequence_data_preparation(
        seq_len, pre_len, train_scaled, test_scaled
    )
    print(trainX.shape)
    print(trainY.shape)
    print(testX.shape)
    print(testY.shape)

    gcn_lstm = GCN_LSTM(
        seq_len=seq_len,
        adj=sensor_dist_adj,
        gc_layer_sizes=[16, 10],
        gc_activations=["relu", "relu"],
        lstm_layer_sizes=[200, 200],
        lstm_activations=["tanh", "tanh"],
    )
    x_input, x_output = gcn_lstm.in_out_tensors()
    model = Model(inputs=x_input, outputs=x_output)
    model.compile(optimizer="adam", loss="mae", metrics=["mse"])
    history = model.fit(
        trainX,
        trainY,
        epochs=100,
        batch_size=60,
        shuffle=True,
        verbose=0,
        validation_data=[testX, testY],
    )
    model.summary()